{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf601e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\GenAI-end-to-end-Medical-ChatBot\\\\research'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "446721e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f10e2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae1c0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b26a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data= load_pdf_file(\"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcde4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c65f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text chuncks 40000\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of text chuncks\", len(text_chunks)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "451d345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    # Use the new import to avoid deprecation warning\n",
    "    try:\n",
    "        from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    except ImportError:\n",
    "        # Fallback to the old import if the new package is not available\n",
    "        from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9f2f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5508f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af35ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "index_name = \"genai-medical-chatbot\"\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99a1b220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Debugging environment variables...\n",
      "Current working directory: d:\\GenAI-end-to-end-Medical-ChatBot\n",
      "‚úÖ Found .env file at: d:\\GenAI-end-to-end-Medical-ChatBot\\.env\n",
      "üìÑ .env file contains 2 lines:\n",
      "  Line 1: PINECONE_API_KEY =***\n",
      "  Line 2: OPENAI_API_KEY =***\n",
      "\n",
      "üîÑ Reloading environment variables...\n",
      "load_dotenv() result: True\n",
      "\n",
      "üîç Environment variable check:\n",
      "PINECONE_API_KEY: ‚úÖ Found\n",
      "OPENAI_API_KEY: ‚úÖ Found\n",
      "OpenAI key starts with: sk-proj...\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check .env file and environment loading\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"üîç Debugging environment variables...\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if .env file exists\n",
    "env_file_path = \".env\"\n",
    "if os.path.exists(env_file_path):\n",
    "    print(f\"‚úÖ Found .env file at: {os.path.abspath(env_file_path)}\")\n",
    "    \n",
    "    # Read and display .env file contents (safely)\n",
    "    with open(env_file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        lines = content.split('\\n')\n",
    "        print(f\"üìÑ .env file contains {len(lines)} lines:\")\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                # Hide actual key values for security\n",
    "                if '=' in line:\n",
    "                    key, value = line.split('=', 1)\n",
    "                    print(f\"  Line {i}: {key}={'***' if value else '(empty)'}\")\n",
    "                else:\n",
    "                    print(f\"  Line {i}: {line}\")\n",
    "            elif line.strip():\n",
    "                print(f\"  Line {i}: {line}\")\n",
    "else:\n",
    "    print(f\"‚ùå No .env file found at: {os.path.abspath(env_file_path)}\")\n",
    "    \n",
    "# Reload environment variables\n",
    "print(\"\\nüîÑ Reloading environment variables...\")\n",
    "load_result = load_dotenv(override=True)\n",
    "print(f\"load_dotenv() result: {load_result}\")\n",
    "\n",
    "# Check environment variables\n",
    "print(f\"\\nüîç Environment variable check:\")\n",
    "pinecone_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "openai_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(f\"PINECONE_API_KEY: {'‚úÖ Found' if pinecone_key else '‚ùå Not found'}\")\n",
    "print(f\"OPENAI_API_KEY: {'‚úÖ Found' if openai_key else '‚ùå Not found'}\")\n",
    "\n",
    "if openai_key:\n",
    "    print(f\"OpenAI key starts with: {openai_key[:7]}...\")\n",
    "else:\n",
    "    print(\"üí° Try checking if your .env file has the correct format:\")\n",
    "    print(\"   OPENAI_API_KEY=sk-your-actual-key-here\")\n",
    "    print(\"   (no spaces around the = sign)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab4526d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index 'genai-medical-chatbot' already exists!\n"
     ]
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "# Check if index already exists\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    try:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,  # Dimension of the embeddings (sentence-transformers/all-MiniLM-L6-v2)\n",
    "            metric=\"cosine\",  # Similarity metric\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\",  # Try us-east-1 instead of us-east-2\n",
    "            )\n",
    "        )\n",
    "        print(f\"‚úÖ Index '{index_name}' created successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating index with us-east-1: {e}\")\n",
    "        print(\"Trying with us-west-2...\")\n",
    "        try:\n",
    "            pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=384,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud=\"aws\",\n",
    "                    region=\"us-west-2\",  # Alternative region\n",
    "                )\n",
    "            )\n",
    "            print(f\"‚úÖ Index '{index_name}' created successfully with us-west-2!\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Error with us-west-2: {e2}\")\n",
    "            print(\"Please check your Pinecone plan and available regions.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Index '{index_name}' already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d752652b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Reloaded environment variables:\n",
      "PINECONE_API_KEY: ‚úÖ Found\n",
      "OPENAI_API_KEY: ‚úÖ Found\n",
      "OpenAI key starts with: sk-proj...\n"
     ]
    }
   ],
   "source": [
    "# Reload environment variables to get the latest values\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "print(f\"üîÑ Reloaded environment variables:\")\n",
    "print(f\"PINECONE_API_KEY: {'‚úÖ Found' if PINECONE_API_KEY else '‚ùå Missing'}\")\n",
    "print(f\"OPENAI_API_KEY: {'‚úÖ Found' if OPENAI_API_KEY else '‚ùå Missing'}\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(f\"OpenAI key starts with: {OPENAI_API_KEY[:7]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b944774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PINECONE_API_KEY set successfully\n",
      "‚úÖ OPENAI_API_KEY set successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check and set environment variables safely\n",
    "if PINECONE_API_KEY:\n",
    "    os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "    print(\"‚úÖ PINECONE_API_KEY set successfully\")\n",
    "else:\n",
    "    print(\"‚ùå PINECONE_API_KEY is not available\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "    print(\"‚úÖ OPENAI_API_KEY set successfully\")\n",
    "else:\n",
    "    print(\"‚ùå OPENAI_API_KEY is not available\")\n",
    "    print(\"üí° Please check your .env file and ensure OPENAI_API_KEY is set\")\n",
    "    print(\"üí° You can also set it manually: OPENAI_API_KEY = 'your-key-here'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e1ad790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec4819d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#existing index\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cef6f93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1f2a2ce7940>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1c61389",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = docsearch.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Number of documents to retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de8ffa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrived_docs = retriver.invoke(\"What is the treatment for diabetes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It was paid :(\n",
    "#from langchain_openai import OpenAI\n",
    "#llm= OpenAI(temperature=0.4, max_tokens=500)\n",
    "#llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.4, max_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a950ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize Ollama model\n",
    "llm = Ollama(model=\"llama3\")  # or \"llama3\", \"gemma\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12b1ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a helpful medical assistant. \"\n",
    "    \"You are assitant for question-answering tasks\"\n",
    "    \"Use the provided documents to answer the user's question accurately and concisely. \"\n",
    "    \"If the information is not available in the documents, respond with 'I don't know'.\"\n",
    "    \"answer concisely in almost 3 lines upto what you feel like is good enough for the user to understand the answer. \"\n",
    "    \"if answer is not available in the documents, respond with basic knowlege \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "858effac",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain = create_retrieval_chain(retriver, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2714e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Gale Encyclopedia of Medicine, acne is a skin disorder where sebaceous glands become inflamed. This occurs due to an increase in sebum production and clogging of pores, leading to pimples forming on the skin.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\" : \"What is acne?\"}) \n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "028514b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The provided documents do not mention artificial intelligence. However, based on general knowledge, artificial intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\" : \"What is artifical intelligence?\"}) \n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
